{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared helper functions\n",
    "\n",
    "def _get_refusal_for_one_response(response) -> bool:\n",
    "    \"\"\"\n",
    "    evaluate whether ONE response is a refusal\n",
    "    \"\"\"\n",
    "    res = False\n",
    "    if response: \n",
    "        keywords = {\"not\", \"no\", \"sorry\", \"don't\", \"doesn't\", \"didn't\", \"can't\", \"couldn't\", \"won't\", \"wouldn't\", \"isn't\", \"unknown\", \"unclear\"}\n",
    "        for target_word in keywords:\n",
    "            negative_keyword_present = re.search(r'\\b' + target_word + r'\\b', response.lower())\n",
    "            if negative_keyword_present:\n",
    "                res = True       \n",
    "                \n",
    "    return res\n",
    "\n",
    "\n",
    "def _get_correctness_for_one_response(response, label) -> bool:\n",
    "    if response:\n",
    "        # our key condition: if any of the labels are in the response, then it is correct\n",
    "        if any([x in response for x in label]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close-source Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_uncertainty_to_int(uncertainty) -> int:\n",
    "    \"\"\"\n",
    "    convert uncertainty to int, e.g. [3] -> 3\n",
    "    \"\"\"\n",
    "    if not uncertainty: # if null\n",
    "        uncertainty = 1\n",
    "    elif \"1\" in uncertainty:\n",
    "        uncertainty = 1\n",
    "    elif \"2\" in uncertainty:\n",
    "        uncertainty = 2\n",
    "    elif \"3\" in uncertainty:\n",
    "        uncertainty = 3\n",
    "    elif \"4\" in uncertainty:\n",
    "        uncertainty = 4\n",
    "    elif \"5\" in uncertainty:\n",
    "        uncertainty = 5\n",
    "    else:\n",
    "        uncertainty = 1 # all other cases, treat as 1\n",
    "    return uncertainty\n",
    "\n",
    "def get_file_and_build_df_close_source(model_name, task_name, task_mode):\n",
    "    # get path\n",
    "    path_response_results = f\"../outputs/Close-source-LLMs_responses/{model_name}\"\n",
    "    path_uncertainty_results = f\"../outputs/Close-source-LLMs_verbalized_uncertainty/{model_name}\"\n",
    "\n",
    "    # get response file\n",
    "    with open(path_response_results + f\"/{model_name}_response_{task_name}_{task_mode}.json\", \"r\") as f_response_results:\n",
    "        response_results = f_response_results.readlines()\n",
    "        response_results = [json.loads(line) for line in response_results]\n",
    "        \n",
    "    # get uncertainty file\n",
    "    with open(path_uncertainty_results + f\"/{model_name}_uncertainty_{task_name}_{task_mode}.json\", \"r\") as f_uncertainty_results:\n",
    "        uncertainty_results = f_uncertainty_results.readlines()\n",
    "        uncertainty_results = [json.loads(line) for line in uncertainty_results]\n",
    "\n",
    "    # construct a dataframe, first column is the question, second column is the response, third column is the uncertainty\n",
    "    df_close_source = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\"])\n",
    "    for i in range(len(response_results)):\n",
    "        df_close_source.loc[i] = [response_results[i][\"prompt\"], \n",
    "                                  model_name, \n",
    "                                  task_name, \n",
    "                                  task_mode, \n",
    "                                  response_results[i][\"label\"], \n",
    "                                  response_results[i][model_name], \n",
    "                                  uncertainty_results[i][model_name]]\n",
    "        \n",
    "    # get the refusal OR correctness for each response\n",
    "    for response in response_results:\n",
    "        correctness = \"NA\"\n",
    "        refusal = \"NA\"\n",
    "        \n",
    "        if task_name == \"RefuNQ\" and task_mode == \"answerable\":\n",
    "            correctness = _get_correctness_for_one_response(response[model_name], response[\"label\"])\n",
    "            response[\"correctness\"] = correctness\n",
    "        else: # for all other tasks\n",
    "            refusal = _get_refusal_for_one_response(response[model_name])\n",
    "            response[\"refusal\"] = refusal\n",
    "            \n",
    "            \n",
    "        df_close_source.loc[df_close_source[\"question\"] == response[\"prompt\"], \"correctness\"] = correctness\n",
    "        df_close_source.loc[df_close_source[\"question\"] == response[\"prompt\"], \"refusal\"] = refusal\n",
    "        \n",
    "    # convert uncertainty to int\n",
    "    df_close_source[\"uncertainty\"] = df_close_source[\"uncertainty\"].apply(_convert_uncertainty_to_int)\n",
    "    \n",
    "    return df_close_source\n",
    "\n",
    "\n",
    "def get_and_combine_all_close_source_df():\n",
    "\n",
    "    model_list = [\"chatgpt\", \"claude\", \"palm\"]\n",
    "    task_list = [\"FalseQA\", \"NEC\", \"RefuNQ\"]\n",
    "    task_mode_list = [\"answerable\", \"unanswerable\"]\n",
    "\n",
    "    df_close_source_all = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\", \"correctness\", \"refusal\"])\n",
    "\n",
    "    for model_name in tqdm(model_list):\n",
    "        for task_name in task_list:\n",
    "            for task_mode in task_mode_list:\n",
    "                print(model_name, task_name, task_mode)\n",
    "                df_close_source = get_file_and_build_df_close_source(model_name, task_name, task_mode)\n",
    "                # get df and concat\n",
    "                df_close_source_all = pd.concat([df_close_source_all, df_close_source])\n",
    "\n",
    "    return df_close_source_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when is the last episode of season 8 of the wa...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[March 18, 2018]</td>\n",
       "      <td>The last episode of season 8 of The Walking De...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the name of the most important jewish ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[the Shulchan Aruch]</td>\n",
       "      <td>The most important Jewish text is the Torah.</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the name of spain's most famous soccer...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Real Madrid]</td>\n",
       "      <td>The name of Spain's most famous soccer team is...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when was the first robot used in surgery</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[1983]</td>\n",
       "      <td>The first robot used in surgery was in 1985.</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where was donovan mitchell picked in the draft</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[13th]</td>\n",
       "      <td>Donovan Mitchell was picked 13th overall in th...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>who sings the song it's raining again</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Supertramp]</td>\n",
       "      <td>Supertramp sings the song \"It's Raining Again.\"</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>who have the most ballon d'or in the history o...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Lionel Messi, Cristiano Ronaldo]</td>\n",
       "      <td>Lionel Messi and Cristiano Ronaldo have the mo...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>who does the voice over in the goldbergs</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Patton Oswalt]</td>\n",
       "      <td>The voice over in The Goldbergs is done by Pat...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Jimmy Matthews]</td>\n",
       "      <td>Ajit Agarkar is the only bowler who has taken ...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>the secretary of state for foreign and commonw...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Boris Johnson]</td>\n",
       "      <td>The current Secretary of State for Foreign and...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question model_name task_name  \\\n",
       "0     when is the last episode of season 8 of the wa...    chatgpt    RefuNQ   \n",
       "1     what is the name of the most important jewish ...    chatgpt    RefuNQ   \n",
       "2     what is the name of spain's most famous soccer...    chatgpt    RefuNQ   \n",
       "3              when was the first robot used in surgery    chatgpt    RefuNQ   \n",
       "4        where was donovan mitchell picked in the draft    chatgpt    RefuNQ   \n",
       "...                                                 ...        ...       ...   \n",
       "2261              who sings the song it's raining again    chatgpt    RefuNQ   \n",
       "2262  who have the most ballon d'or in the history o...    chatgpt    RefuNQ   \n",
       "2263           who does the voice over in the goldbergs    chatgpt    RefuNQ   \n",
       "2264  who is the only bowler who have taken hattrick...    chatgpt    RefuNQ   \n",
       "2265  the secretary of state for foreign and commonw...    chatgpt    RefuNQ   \n",
       "\n",
       "       task_mode                              label  \\\n",
       "0     answerable                   [March 18, 2018]   \n",
       "1     answerable               [the Shulchan Aruch]   \n",
       "2     answerable                      [Real Madrid]   \n",
       "3     answerable                             [1983]   \n",
       "4     answerable                             [13th]   \n",
       "...          ...                                ...   \n",
       "2261  answerable                       [Supertramp]   \n",
       "2262  answerable  [Lionel Messi, Cristiano Ronaldo]   \n",
       "2263  answerable                    [Patton Oswalt]   \n",
       "2264  answerable                   [Jimmy Matthews]   \n",
       "2265  answerable                    [Boris Johnson]   \n",
       "\n",
       "                                               response uncertainty  \\\n",
       "0     The last episode of season 8 of The Walking De...           2   \n",
       "1          The most important Jewish text is the Torah.           3   \n",
       "2     The name of Spain's most famous soccer team is...           4   \n",
       "3          The first robot used in surgery was in 1985.           3   \n",
       "4     Donovan Mitchell was picked 13th overall in th...           3   \n",
       "...                                                 ...         ...   \n",
       "2261    Supertramp sings the song \"It's Raining Again.\"           3   \n",
       "2262  Lionel Messi and Cristiano Ronaldo have the mo...           3   \n",
       "2263  The voice over in The Goldbergs is done by Pat...           2   \n",
       "2264  Ajit Agarkar is the only bowler who has taken ...           3   \n",
       "2265  The current Secretary of State for Foreign and...           2   \n",
       "\n",
       "     correctness refusal  \n",
       "0          False      NA  \n",
       "1          False      NA  \n",
       "2           True      NA  \n",
       "3          False      NA  \n",
       "4           True      NA  \n",
       "...          ...     ...  \n",
       "2261        True      NA  \n",
       "2262        True      NA  \n",
       "2263        True      NA  \n",
       "2264       False      NA  \n",
       "2265       False      NA  \n",
       "\n",
       "[2266 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_and_build_df_close_source(\"chatgpt\", \"RefuNQ\", \"answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:51<00:00, 17.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List the reason why cats can catch mice?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Cats can catch mice due to their natural hunti...</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many legs does an idiot have?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>An idiot has the same number of legs as any ot...</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What colour are the swallows's feathers?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>The color of a swallow's feathers can vary, bu...</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When warm air is lighter than cold air, what w...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>When warm air is lighter than cold air, it wil...</td>\n",
       "      <td>4</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can we follow the schedule to make a plan</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, following a schedule can help in making a...</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>who sings the Alerrawia it's raining again</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The song \"Alerrawia It's Raining Again\" is sun...</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>who have the most Regalawsuisted d'or in the h...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Lionel Messi has won the most Ballon d'Or awar...</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>who does the voice over in the Requirtion</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The voice over in the Requirtion is done by th...</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The only bowler to take a hat-trick in both in...</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>the secretary of state for foreign and Looncan...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Liz Truss is the current Secretary of State fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39957 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question model_name task_name  \\\n",
       "0              List the reason why cats can catch mice?    chatgpt   FalseQA   \n",
       "1                     How many legs does an idiot have?    chatgpt   FalseQA   \n",
       "2              What colour are the swallows's feathers?    chatgpt   FalseQA   \n",
       "3     When warm air is lighter than cold air, what w...    chatgpt   FalseQA   \n",
       "4             can we follow the schedule to make a plan    chatgpt   FalseQA   \n",
       "...                                                 ...        ...       ...   \n",
       "2168         who sings the Alerrawia it's raining again       palm    RefuNQ   \n",
       "2169  who have the most Regalawsuisted d'or in the h...       palm    RefuNQ   \n",
       "2170          who does the voice over in the Requirtion       palm    RefuNQ   \n",
       "2171  who is the only bowler who have taken hattrick...       palm    RefuNQ   \n",
       "2172  the secretary of state for foreign and Looncan...       palm    RefuNQ   \n",
       "\n",
       "         task_mode label                                           response  \\\n",
       "0       answerable     0  Cats can catch mice due to their natural hunti...   \n",
       "1       answerable     0  An idiot has the same number of legs as any ot...   \n",
       "2       answerable     0  The color of a swallow's feathers can vary, bu...   \n",
       "3       answerable     0  When warm air is lighter than cold air, it wil...   \n",
       "4       answerable     0  Yes, following a schedule can help in making a...   \n",
       "...            ...   ...                                                ...   \n",
       "2168  unanswerable   NEC  The song \"Alerrawia It's Raining Again\" is sun...   \n",
       "2169  unanswerable   NEC  Lionel Messi has won the most Ballon d'Or awar...   \n",
       "2170  unanswerable   NEC  The voice over in the Requirtion is done by th...   \n",
       "2171  unanswerable   NEC  The only bowler to take a hat-trick in both in...   \n",
       "2172  unanswerable   NEC  Liz Truss is the current Secretary of State fo...   \n",
       "\n",
       "     uncertainty correctness refusal  \n",
       "0              3          NA   False  \n",
       "1              1          NA   False  \n",
       "2              2          NA   False  \n",
       "3              4          NA   False  \n",
       "4              2          NA   False  \n",
       "...          ...         ...     ...  \n",
       "2168           3          NA   False  \n",
       "2169           3          NA   False  \n",
       "2170           3          NA   False  \n",
       "2171           3          NA   False  \n",
       "2172           2          NA   False  \n",
       "\n",
       "[39957 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes about 1 min to run\n",
    "df_close_source_all = get_and_combine_all_close_source_df()\n",
    "df_close_source_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-source Llama-2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_and_build_df_llama(model_name, task_name, task_mode):\n",
    "    # get path\n",
    "    path_response_results = f\"../outputs/Llama-2_responses/{model_name}\"\n",
    "    path_uncertainty_results = f\"../outputs/Llama-2_logit_based_uncertainty/{model_name}\"\n",
    "\n",
    "    # get response file\n",
    "    with open(path_response_results + f\"/{model_name}_{task_name}_{task_mode}.json\", \"r\") as f_response_results:\n",
    "        response_results = f_response_results.readlines()\n",
    "        response_results = [json.loads(line) for line in response_results]\n",
    "        \n",
    "    # get uncertainty file\n",
    "    with open(path_uncertainty_results + f\"/{model_name}_{task_name}_{task_mode}.json\", \"r\") as f_uncertainty_results:\n",
    "        uncertainty_results = f_uncertainty_results.readlines()\n",
    "        uncertainty_results = [json.loads(line) for line in uncertainty_results]\n",
    "\n",
    "    # construct df\n",
    "    df_llama = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"entropy\", \"perplexity\"])\n",
    "    for i in range(len(response_results)):\n",
    "        df_llama.loc[i] = [response_results[i][\"prompt\"], \n",
    "                            model_name, \n",
    "                            task_name, \n",
    "                            task_mode, \n",
    "                            response_results[i][\"label\"], \n",
    "                            response_results[i][f\"{model_name}_response\"], \n",
    "                            uncertainty_results[i][f\"{model_name}_entropy\"],\n",
    "                            uncertainty_results[i][f\"{model_name}_perplexity\"]]\n",
    "        \n",
    "    # get the refusal OR correctness for each response\n",
    "    for response in response_results:\n",
    "        correctness = \"NA\"\n",
    "        refusal = \"NA\"\n",
    "        \n",
    "        if task_name == \"RefuNQ\" and task_mode == \"answerable\":\n",
    "            correctness = _get_correctness_for_one_response(f\"{model_name}_response\", response[\"label\"])\n",
    "            response[\"correctness\"] = correctness\n",
    "        else: # for all other tasks\n",
    "            refusal = _get_refusal_for_one_response(response[f\"{model_name}_response\"])\n",
    "            response[\"refusal\"] = refusal\n",
    "            \n",
    "            \n",
    "        df_llama.loc[df_llama[\"question\"] == response[\"prompt\"], \"correctness\"] = correctness\n",
    "        df_llama.loc[df_llama[\"question\"] == response[\"prompt\"], \"refusal\"] = refusal\n",
    "    \n",
    "    return df_llama\n",
    "\n",
    "\n",
    "def get_and_combine_all_llama_df():\n",
    "\n",
    "    llama_2_model_list = [\n",
    "        \"Llama-2-7b-chat-hf\",\n",
    "        \"Llama-2-7b-hf\",\n",
    "        \"Llama-2-13b-chat-hf\",\n",
    "        \"Llama-2-13b-hf\",\n",
    "        \"Llama-2-70b-chat-hf\",\n",
    "        \"Llama-2-70b-hf\"\n",
    "    ]\n",
    "    task_list = [\"FalseQA\", \"NEC\", \"RefuNQ\"]\n",
    "    task_mode_list = [\"answerable\", \"unanswerable\"]\n",
    "\n",
    "    df_llama_all = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\", \"correctness\", \"refusal\"])\n",
    "\n",
    "    for model_name in tqdm(llama_2_model_list):\n",
    "        for task_name in task_list:\n",
    "            for task_mode in task_mode_list:\n",
    "                print(model_name, task_name, task_mode)\n",
    "                df_llama = get_file_and_build_df_llama(model_name, task_name, task_mode)\n",
    "                # get df and concat\n",
    "                df_llama_all = pd.concat([df_llama_all, df_llama])\n",
    "\n",
    "    return df_llama_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:46<00:00, 17.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "      <th>entropy</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List the reason why cats can catch mice?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Cats can catch mice due to their agility, spe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093158</td>\n",
       "      <td>224.947464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many legs does an idiot have?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>I apologize, but I cannot provide an answer t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1.188019</td>\n",
       "      <td>140.602753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What colour are the swallows's feathers?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>The swallows' feathers are blue-gray in color.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>160.510925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When warm air is lighter than cold air, what w...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>When warm air is lighter than cold air, it wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>149.398468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can we follow the schedule to make a plan</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, you can follow a schedule to make a plan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>273.737396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>who sings the Alerrawia it's raining again?</td>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The song is sung by the band Supertramp.\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>5.436124</td>\n",
       "      <td>28.175888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>who have the most Regalawsuisted d'or in the h...</td>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Cristiano Ronaldo\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>4.367566</td>\n",
       "      <td>32.408855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>who does the voice over in the Requirtion?</td>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The voice over is done by the director of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>5.821088</td>\n",
       "      <td>20.552803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Wasim Akram\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>5.002635</td>\n",
       "      <td>16.606394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>the secretary of state for foreign and Looncan...</td>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The Secretary of State for Foreign and Commonw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>4.341969</td>\n",
       "      <td>20.380131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79914 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question          model_name  \\\n",
       "0              List the reason why cats can catch mice?  Llama-2-7b-chat-hf   \n",
       "1                     How many legs does an idiot have?  Llama-2-7b-chat-hf   \n",
       "2              What colour are the swallows's feathers?  Llama-2-7b-chat-hf   \n",
       "3     When warm air is lighter than cold air, what w...  Llama-2-7b-chat-hf   \n",
       "4             can we follow the schedule to make a plan  Llama-2-7b-chat-hf   \n",
       "...                                                 ...                 ...   \n",
       "2168        who sings the Alerrawia it's raining again?      Llama-2-70b-hf   \n",
       "2169  who have the most Regalawsuisted d'or in the h...      Llama-2-70b-hf   \n",
       "2170         who does the voice over in the Requirtion?      Llama-2-70b-hf   \n",
       "2171  who is the only bowler who have taken hattrick...      Llama-2-70b-hf   \n",
       "2172  the secretary of state for foreign and Looncan...      Llama-2-70b-hf   \n",
       "\n",
       "     task_name     task_mode label  \\\n",
       "0      FalseQA    answerable     0   \n",
       "1      FalseQA    answerable     0   \n",
       "2      FalseQA    answerable     0   \n",
       "3      FalseQA    answerable     0   \n",
       "4      FalseQA    answerable     0   \n",
       "...        ...           ...   ...   \n",
       "2168    RefuNQ  unanswerable   NEC   \n",
       "2169    RefuNQ  unanswerable   NEC   \n",
       "2170    RefuNQ  unanswerable   NEC   \n",
       "2171    RefuNQ  unanswerable   NEC   \n",
       "2172    RefuNQ  unanswerable   NEC   \n",
       "\n",
       "                                               response uncertainty  \\\n",
       "0      Cats can catch mice due to their agility, spe...         NaN   \n",
       "1      I apologize, but I cannot provide an answer t...         NaN   \n",
       "2        The swallows' feathers are blue-gray in color.         NaN   \n",
       "3      When warm air is lighter than cold air, it wi...         NaN   \n",
       "4      Yes, you can follow a schedule to make a plan...         NaN   \n",
       "...                                                 ...         ...   \n",
       "2168         The song is sung by the band Supertramp.\\n         NaN   \n",
       "2169                                Cristiano Ronaldo\\n         NaN   \n",
       "2170  The voice over is done by the director of the ...         NaN   \n",
       "2171                                      Wasim Akram\\n         NaN   \n",
       "2172  The Secretary of State for Foreign and Commonw...         NaN   \n",
       "\n",
       "     correctness refusal   entropy  perplexity  \n",
       "0             NA   False  0.093158  224.947464  \n",
       "1             NA    True  1.188019  140.602753  \n",
       "2             NA   False  0.091228  160.510925  \n",
       "3             NA   False  0.196143  149.398468  \n",
       "4             NA   False  0.227807  273.737396  \n",
       "...          ...     ...       ...         ...  \n",
       "2168          NA   False  5.436124   28.175888  \n",
       "2169          NA   False  4.367566   32.408855  \n",
       "2170          NA   False  5.821088   20.552803  \n",
       "2171          NA   False  5.002635   16.606394  \n",
       "2172          NA   False  4.341969   20.380131  \n",
       "\n",
       "[79914 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes about 2 mins to run\n",
    "df_llama_all = get_and_combine_all_llama_df()\n",
    "df_llama_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_close_source_all.to_csv(\"../outputs/df_close_source_all.csv\", index=False)\n",
    "df_llama_all.to_csv(\"../outputs/df_llama_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
