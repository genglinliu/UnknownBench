{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared helper functions\n",
    "\n",
    "def _get_refusal_for_one_response(response) -> bool:\n",
    "    \"\"\"\n",
    "    evaluate whether ONE response is a refusal\n",
    "    \"\"\"\n",
    "    res = False\n",
    "    if response: \n",
    "        keywords = {\"not\", \"no\", \"sorry\", \"don't\", \"doesn't\", \"didn't\", \"can't\", \"couldn't\", \"won't\", \"wouldn't\", \"isn't\", \"unknown\", \"unclear\"}\n",
    "        for target_word in keywords:\n",
    "            negative_keyword_present = re.search(r'\\b' + target_word + r'\\b', response.lower())\n",
    "            if negative_keyword_present:\n",
    "                res = True       \n",
    "                \n",
    "    return res\n",
    "\n",
    "\n",
    "def _get_correctness_for_one_response(response, label) -> bool:\n",
    "    if response:\n",
    "        # our key condition: if any of the labels are in the response, then it is correct\n",
    "        if any([x in response for x in label]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close-source Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_and_build_df_close_source(model_name, task_name, task_mode):\n",
    "    # get path\n",
    "    path_response_results = f\"../outputs/Close-source-LLMs_responses/{model_name}\"\n",
    "    path_uncertainty_results = f\"../../experiment_outputs/UNIFIED_verbalize_confidence_no_ICL/{model_name}\"\n",
    "\n",
    "    # get response file\n",
    "    with open(path_response_results + f\"/{model_name}_response_{task_name}_{task_mode}.json\", \"r\") as f_response_results:\n",
    "        response_results = f_response_results.readlines()\n",
    "        response_results = [json.loads(line) for line in response_results]\n",
    "        \n",
    "    # get uncertainty file\n",
    "    with open(path_uncertainty_results + f\"/{model_name}_{task_name}_{task_mode}.json\", \"r\") as f_uncertainty_results:\n",
    "        uncertainty_results = f_uncertainty_results.readlines()\n",
    "        uncertainty_results = [json.loads(line) for line in uncertainty_results]\n",
    "\n",
    "    # construct a dataframe, first column is the question, second column is the response, third column is the uncertainty\n",
    "    df_close_source = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\"])\n",
    "    for i in range(len(response_results)):\n",
    "        df_close_source.loc[i] = [response_results[i][\"prompt\"], \n",
    "                                  model_name, \n",
    "                                  task_name, \n",
    "                                  task_mode, \n",
    "                                  response_results[i][\"label\"], \n",
    "                                  response_results[i][model_name], \n",
    "                                  uncertainty_results[i][model_name + \"_numerical\"]]\n",
    "        \n",
    "    # get the refusal OR correctness for each response\n",
    "    for response in response_results:\n",
    "        correctness = \"NA\"\n",
    "        refusal = \"NA\"\n",
    "        \n",
    "        if task_name == \"RefuNQ\" and task_mode == \"answerable\":\n",
    "            correctness = _get_correctness_for_one_response(response[model_name], response[\"label\"])\n",
    "            response[\"correctness\"] = correctness\n",
    "        else: # for all other tasks\n",
    "            refusal = _get_refusal_for_one_response(response[model_name])\n",
    "            response[\"refusal\"] = refusal\n",
    "            \n",
    "            \n",
    "        df_close_source.loc[df_close_source[\"question\"] == response[\"prompt\"], \"correctness\"] = correctness\n",
    "        df_close_source.loc[df_close_source[\"question\"] == response[\"prompt\"], \"refusal\"] = refusal\n",
    "        \n",
    "    \n",
    "    return df_close_source\n",
    "\n",
    "\n",
    "def get_and_combine_all_close_source_df():\n",
    "\n",
    "    model_list = [\"chatgpt\", \"claude\", \"palm\"]\n",
    "    task_list = [\"FalseQA\", \"NEC\", \"RefuNQ\"]\n",
    "    task_mode_list = [\"answerable\", \"unanswerable\"]\n",
    "\n",
    "    df_close_source_all = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\", \"correctness\", \"refusal\"])\n",
    "\n",
    "    for model_name in tqdm(model_list):\n",
    "        for task_name in task_list:\n",
    "            for task_mode in task_mode_list:\n",
    "                print(model_name, task_name, task_mode)\n",
    "                df_close_source = get_file_and_build_df_close_source(model_name, task_name, task_mode)\n",
    "                # get df and concat\n",
    "                df_close_source_all = pd.concat([df_close_source_all, df_close_source])\n",
    "\n",
    "    return df_close_source_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when is the last episode of season 8 of the wa...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[March 18, 2018]</td>\n",
       "      <td>The last episode of season 8 of The Walking De...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the name of the most important jewish ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[the Shulchan Aruch]</td>\n",
       "      <td>The most important Jewish text is the Torah.</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the name of spain's most famous soccer...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Real Madrid]</td>\n",
       "      <td>The name of Spain's most famous soccer team is...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when was the first robot used in surgery</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[1983]</td>\n",
       "      <td>The first robot used in surgery was in 1985.</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where was donovan mitchell picked in the draft</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[13th]</td>\n",
       "      <td>Donovan Mitchell was picked 13th overall in th...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>who sings the song it's raining again</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Supertramp]</td>\n",
       "      <td>Supertramp sings the song \"It's Raining Again.\"</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>who have the most ballon d'or in the history o...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Lionel Messi, Cristiano Ronaldo]</td>\n",
       "      <td>Lionel Messi and Cristiano Ronaldo have the mo...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>who does the voice over in the goldbergs</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Patton Oswalt]</td>\n",
       "      <td>The voice over in The Goldbergs is done by Pat...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Jimmy Matthews]</td>\n",
       "      <td>Ajit Agarkar is the only bowler who has taken ...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>the secretary of state for foreign and commonw...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>answerable</td>\n",
       "      <td>[Boris Johnson]</td>\n",
       "      <td>The current Secretary of State for Foreign and...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question model_name task_name  \\\n",
       "0     when is the last episode of season 8 of the wa...    chatgpt    RefuNQ   \n",
       "1     what is the name of the most important jewish ...    chatgpt    RefuNQ   \n",
       "2     what is the name of spain's most famous soccer...    chatgpt    RefuNQ   \n",
       "3              when was the first robot used in surgery    chatgpt    RefuNQ   \n",
       "4        where was donovan mitchell picked in the draft    chatgpt    RefuNQ   \n",
       "...                                                 ...        ...       ...   \n",
       "2261              who sings the song it's raining again    chatgpt    RefuNQ   \n",
       "2262  who have the most ballon d'or in the history o...    chatgpt    RefuNQ   \n",
       "2263           who does the voice over in the goldbergs    chatgpt    RefuNQ   \n",
       "2264  who is the only bowler who have taken hattrick...    chatgpt    RefuNQ   \n",
       "2265  the secretary of state for foreign and commonw...    chatgpt    RefuNQ   \n",
       "\n",
       "       task_mode                              label  \\\n",
       "0     answerable                   [March 18, 2018]   \n",
       "1     answerable               [the Shulchan Aruch]   \n",
       "2     answerable                      [Real Madrid]   \n",
       "3     answerable                             [1983]   \n",
       "4     answerable                             [13th]   \n",
       "...          ...                                ...   \n",
       "2261  answerable                       [Supertramp]   \n",
       "2262  answerable  [Lionel Messi, Cristiano Ronaldo]   \n",
       "2263  answerable                    [Patton Oswalt]   \n",
       "2264  answerable                   [Jimmy Matthews]   \n",
       "2265  answerable                    [Boris Johnson]   \n",
       "\n",
       "                                               response  uncertainty  \\\n",
       "0     The last episode of season 8 of The Walking De...            8   \n",
       "1          The most important Jewish text is the Torah.            8   \n",
       "2     The name of Spain's most famous soccer team is...            9   \n",
       "3          The first robot used in surgery was in 1985.            8   \n",
       "4     Donovan Mitchell was picked 13th overall in th...            8   \n",
       "...                                                 ...          ...   \n",
       "2261    Supertramp sings the song \"It's Raining Again.\"            8   \n",
       "2262  Lionel Messi and Cristiano Ronaldo have the mo...            8   \n",
       "2263  The voice over in The Goldbergs is done by Pat...            8   \n",
       "2264  Ajit Agarkar is the only bowler who has taken ...            8   \n",
       "2265  The current Secretary of State for Foreign and...            8   \n",
       "\n",
       "     correctness refusal  \n",
       "0          False      NA  \n",
       "1          False      NA  \n",
       "2           True      NA  \n",
       "3          False      NA  \n",
       "4           True      NA  \n",
       "...          ...     ...  \n",
       "2261        True      NA  \n",
       "2262        True      NA  \n",
       "2263        True      NA  \n",
       "2264       False      NA  \n",
       "2265       False      NA  \n",
       "\n",
       "[2266 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_and_build_df_close_source(\"chatgpt\", \"RefuNQ\", \"answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt FalseQA answerable\n",
      "chatgpt FalseQA unanswerable\n",
      "chatgpt NEC answerable\n",
      "chatgpt NEC unanswerable\n",
      "chatgpt RefuNQ answerable\n",
      "chatgpt RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:16<00:32, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude FalseQA answerable\n",
      "claude FalseQA unanswerable\n",
      "claude NEC answerable\n",
      "claude NEC unanswerable\n",
      "claude RefuNQ answerable\n",
      "claude RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:33<00:16, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palm FalseQA answerable\n",
      "palm FalseQA unanswerable\n",
      "palm NEC answerable\n",
      "palm NEC unanswerable\n",
      "palm RefuNQ answerable\n",
      "palm RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:50<00:00, 16.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List the reason why cats can catch mice?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Cats can catch mice due to their natural hunti...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many legs does an idiot have?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>An idiot has the same number of legs as any ot...</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What colour are the swallows's feathers?</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>The color of a swallow's feathers can vary, bu...</td>\n",
       "      <td>7</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When warm air is lighter than cold air, what w...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>When warm air is lighter than cold air, it wil...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can we follow the schedule to make a plan</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, following a schedule can help in making a...</td>\n",
       "      <td>7</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>who sings the Alerrawia it's raining again</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The song \"Alerrawia It's Raining Again\" is sun...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>who have the most Regalawsuisted d'or in the h...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Lionel Messi has won the most Ballon d'Or awar...</td>\n",
       "      <td>9</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>who does the voice over in the Requirtion</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The voice over in the Requirtion is done by th...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The only bowler to take a hat-trick in both in...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>the secretary of state for foreign and Looncan...</td>\n",
       "      <td>palm</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Liz Truss is the current Secretary of State fo...</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39957 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question model_name task_name  \\\n",
       "0              List the reason why cats can catch mice?    chatgpt   FalseQA   \n",
       "1                     How many legs does an idiot have?    chatgpt   FalseQA   \n",
       "2              What colour are the swallows's feathers?    chatgpt   FalseQA   \n",
       "3     When warm air is lighter than cold air, what w...    chatgpt   FalseQA   \n",
       "4             can we follow the schedule to make a plan    chatgpt   FalseQA   \n",
       "...                                                 ...        ...       ...   \n",
       "2168         who sings the Alerrawia it's raining again       palm    RefuNQ   \n",
       "2169  who have the most Regalawsuisted d'or in the h...       palm    RefuNQ   \n",
       "2170          who does the voice over in the Requirtion       palm    RefuNQ   \n",
       "2171  who is the only bowler who have taken hattrick...       palm    RefuNQ   \n",
       "2172  the secretary of state for foreign and Looncan...       palm    RefuNQ   \n",
       "\n",
       "         task_mode label                                           response  \\\n",
       "0       answerable     0  Cats can catch mice due to their natural hunti...   \n",
       "1       answerable     0  An idiot has the same number of legs as any ot...   \n",
       "2       answerable     0  The color of a swallow's feathers can vary, bu...   \n",
       "3       answerable     0  When warm air is lighter than cold air, it wil...   \n",
       "4       answerable     0  Yes, following a schedule can help in making a...   \n",
       "...            ...   ...                                                ...   \n",
       "2168  unanswerable   NEC  The song \"Alerrawia It's Raining Again\" is sun...   \n",
       "2169  unanswerable   NEC  Lionel Messi has won the most Ballon d'Or awar...   \n",
       "2170  unanswerable   NEC  The voice over in the Requirtion is done by th...   \n",
       "2171  unanswerable   NEC  The only bowler to take a hat-trick in both in...   \n",
       "2172  unanswerable   NEC  Liz Truss is the current Secretary of State fo...   \n",
       "\n",
       "     uncertainty correctness refusal  \n",
       "0              8          NA   False  \n",
       "1              2          NA   False  \n",
       "2              7          NA   False  \n",
       "3              8          NA   False  \n",
       "4              7          NA   False  \n",
       "...          ...         ...     ...  \n",
       "2168           8          NA   False  \n",
       "2169           9          NA   False  \n",
       "2170           8          NA   False  \n",
       "2171           8          NA   False  \n",
       "2172           8          NA   False  \n",
       "\n",
       "[39957 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes about 1 min to run\n",
    "df_close_source_all = get_and_combine_all_close_source_df()\n",
    "df_close_source_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close_source_all.to_csv(\"../outputs/df_close_source_all_unified_no_ICL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-source Llama-2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_and_build_df_open_source(model_name, task_name, task_mode):\n",
    "    # get path\n",
    "    path_response_results = f\"../outputs/Open-source-LLMs_responses/{model_name}\"\n",
    "    path_uncertainty_results = f\"../outputs/unified_confidence_extracted_scores/{model_name}\"\n",
    "\n",
    "    # get response file\n",
    "    with open(path_response_results + f\"/{model_name}_{task_name}_{task_mode}.json\", \"r\") as f_response_results:\n",
    "        response_results = f_response_results.readlines()\n",
    "        response_results = [json.loads(line) for line in response_results]\n",
    "        \n",
    "    # get uncertainty file\n",
    "    with open(path_uncertainty_results + f\"/{model_name}_{task_name}_{task_mode}.json\", \"r\") as f_uncertainty_results:\n",
    "        uncertainty_results = f_uncertainty_results.readlines()\n",
    "        uncertainty_results = [json.loads(line) for line in uncertainty_results]\n",
    "\n",
    "    # construct a dataframe, first column is the question, second column is the response, third column is the uncertainty\n",
    "    df_open_source = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\"])\n",
    "    for i in range(len(response_results)):\n",
    "        df_open_source.loc[i] = [response_results[i][\"prompt\"], \n",
    "                                  model_name, \n",
    "                                  task_name, \n",
    "                                  task_mode, \n",
    "                                  response_results[i][\"label\"], \n",
    "                                  response_results[i][model_name + \"_response\"], \n",
    "                                  uncertainty_results[i][model_name + \"_numerical\"]]\n",
    "        \n",
    "    # get the refusal OR correctness for each response\n",
    "    for response in response_results:\n",
    "        correctness = \"NA\"\n",
    "        refusal = \"NA\"\n",
    "        \n",
    "        if task_name == \"RefuNQ\" and task_mode == \"answerable\":\n",
    "            correctness = _get_correctness_for_one_response(response[model_name + \"_response\"], response[\"label\"])\n",
    "            response[\"correctness\"] = correctness\n",
    "        else: # for all other tasks\n",
    "            refusal = _get_refusal_for_one_response(response[model_name + \"_response\"])\n",
    "            response[\"refusal\"] = refusal\n",
    "            \n",
    "            \n",
    "        df_open_source.loc[df_open_source[\"question\"] == response[\"prompt\"], \"correctness\"] = correctness\n",
    "        df_open_source.loc[df_open_source[\"question\"] == response[\"prompt\"], \"refusal\"] = refusal\n",
    "        \n",
    "    \n",
    "    return df_open_source\n",
    "\n",
    "\n",
    "def get_and_combine_all_open_source_df():\n",
    "\n",
    "    model_list = [\n",
    "        \"Llama-2-7b-chat-hf\",\n",
    "        \"Llama-2-7b-hf\",\n",
    "        \"Llama-2-13b-chat-hf\",\n",
    "        \"Llama-2-13b-hf\",\n",
    "        # \"Llama-2-70b-chat-hf\",\n",
    "        # \"Llama-2-70b-hf\",\n",
    "        \"vicuna-7b-v1.5\",\n",
    "        \"vicuna-13b-v1.5\"\n",
    "    ]\n",
    "    task_list = [\"FalseQA\", \"NEC\", \"RefuNQ\"]\n",
    "    task_mode_list = [\"answerable\", \"unanswerable\"]\n",
    "\n",
    "    df_open_source_all = pd.DataFrame(columns=[\"question\", \"model_name\", \"task_name\", \"task_mode\", \"label\", \"response\", \"uncertainty\", \"correctness\", \"refusal\"])\n",
    "\n",
    "    for model_name in tqdm(model_list):\n",
    "        for task_name in task_list:\n",
    "            for task_mode in task_mode_list:\n",
    "                print(model_name, task_name, task_mode)\n",
    "                df_open_source = get_file_and_build_df_open_source(model_name, task_name, task_mode)\n",
    "                # get df and concat\n",
    "                df_open_source_all = pd.concat([df_open_source_all, df_open_source])\n",
    "\n",
    "    return df_open_source_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when is the last Buquor of season 8 of the wal...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The last episode of Season 8 of The Walking D...</td>\n",
       "      <td>52</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the name of the most important jewish ...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The most important Jewish philosophical text ...</td>\n",
       "      <td>50</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the name of spain's most famous soccer...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The name of Spain's most famous soccer refere...</td>\n",
       "      <td>62</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when was the first Diwherter used in surgery?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The first Diwherter was used in surgery in 19...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where was donovan mitchell picked in the Froni...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Donovan Mitchell was picked 13th overall in t...</td>\n",
       "      <td>52</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>who sings the Alerrawia it's raining again?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The song \"Alerrawia\" is performed by the Japa...</td>\n",
       "      <td>52</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>who have the most Regalawsuisted d'or in the h...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The Brazilian national football team has won ...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>who does the voice over in the Requirtion?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The voice over in the Region is provided by a...</td>\n",
       "      <td>5</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The only bowler to take a hat-trick in both i...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>the secretary of state for foreign and Looncan...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The current Secretary of State for Foreign an...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2173 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question          model_name  \\\n",
       "0     when is the last Buquor of season 8 of the wal...  Llama-2-7b-chat-hf   \n",
       "1     what is the name of the most important jewish ...  Llama-2-7b-chat-hf   \n",
       "2     what is the name of spain's most famous soccer...  Llama-2-7b-chat-hf   \n",
       "3         when was the first Diwherter used in surgery?  Llama-2-7b-chat-hf   \n",
       "4     where was donovan mitchell picked in the Froni...  Llama-2-7b-chat-hf   \n",
       "...                                                 ...                 ...   \n",
       "2168        who sings the Alerrawia it's raining again?  Llama-2-7b-chat-hf   \n",
       "2169  who have the most Regalawsuisted d'or in the h...  Llama-2-7b-chat-hf   \n",
       "2170         who does the voice over in the Requirtion?  Llama-2-7b-chat-hf   \n",
       "2171  who is the only bowler who have taken hattrick...  Llama-2-7b-chat-hf   \n",
       "2172  the secretary of state for foreign and Looncan...  Llama-2-7b-chat-hf   \n",
       "\n",
       "     task_name     task_mode label  \\\n",
       "0       RefuNQ  unanswerable   NEC   \n",
       "1       RefuNQ  unanswerable   NEC   \n",
       "2       RefuNQ  unanswerable   NEC   \n",
       "3       RefuNQ  unanswerable   NEC   \n",
       "4       RefuNQ  unanswerable   NEC   \n",
       "...        ...           ...   ...   \n",
       "2168    RefuNQ  unanswerable   NEC   \n",
       "2169    RefuNQ  unanswerable   NEC   \n",
       "2170    RefuNQ  unanswerable   NEC   \n",
       "2171    RefuNQ  unanswerable   NEC   \n",
       "2172    RefuNQ  unanswerable   NEC   \n",
       "\n",
       "                                               response uncertainty  \\\n",
       "0      The last episode of Season 8 of The Walking D...          52   \n",
       "1      The most important Jewish philosophical text ...          50   \n",
       "2      The name of Spain's most famous soccer refere...          62   \n",
       "3      The first Diwherter was used in surgery in 19...          85   \n",
       "4      Donovan Mitchell was picked 13th overall in t...          52   \n",
       "...                                                 ...         ...   \n",
       "2168   The song \"Alerrawia\" is performed by the Japa...          52   \n",
       "2169   The Brazilian national football team has won ...          85   \n",
       "2170   The voice over in the Region is provided by a...           5   \n",
       "2171   The only bowler to take a hat-trick in both i...          85   \n",
       "2172   The current Secretary of State for Foreign an...          85   \n",
       "\n",
       "     correctness refusal  \n",
       "0             NA   False  \n",
       "1             NA   False  \n",
       "2             NA   False  \n",
       "3             NA   False  \n",
       "4             NA   False  \n",
       "...          ...     ...  \n",
       "2168          NA   False  \n",
       "2169          NA   False  \n",
       "2170          NA   False  \n",
       "2171          NA   False  \n",
       "2172          NA   False  \n",
       "\n",
       "[2173 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on one df\n",
    "\n",
    "get_file_and_build_df_open_source(\"Llama-2-7b-chat-hf\", \"RefuNQ\", \"unanswerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-2-7b-chat-hf FalseQA answerable\n",
      "Llama-2-7b-chat-hf FalseQA unanswerable\n",
      "Llama-2-7b-chat-hf NEC answerable\n",
      "Llama-2-7b-chat-hf NEC unanswerable\n",
      "Llama-2-7b-chat-hf RefuNQ answerable\n",
      "Llama-2-7b-chat-hf RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:17<01:27, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-2-7b-hf FalseQA answerable\n",
      "Llama-2-7b-hf FalseQA unanswerable\n",
      "Llama-2-7b-hf NEC answerable\n",
      "Llama-2-7b-hf NEC unanswerable\n",
      "Llama-2-7b-hf RefuNQ answerable\n",
      "Llama-2-7b-hf RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:34<01:09, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-2-13b-chat-hf FalseQA answerable\n",
      "Llama-2-13b-chat-hf FalseQA unanswerable\n",
      "Llama-2-13b-chat-hf NEC answerable\n",
      "Llama-2-13b-chat-hf NEC unanswerable\n",
      "Llama-2-13b-chat-hf RefuNQ answerable\n",
      "Llama-2-13b-chat-hf RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:52, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-2-13b-hf FalseQA answerable\n",
      "Llama-2-13b-hf FalseQA unanswerable\n",
      "Llama-2-13b-hf NEC answerable\n",
      "Llama-2-13b-hf NEC unanswerable\n",
      "Llama-2-13b-hf RefuNQ answerable\n",
      "Llama-2-13b-hf RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:09<00:34, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vicuna-7b-v1.5 FalseQA answerable\n",
      "vicuna-7b-v1.5 FalseQA unanswerable\n",
      "vicuna-7b-v1.5 NEC answerable\n",
      "vicuna-7b-v1.5 NEC unanswerable\n",
      "vicuna-7b-v1.5 RefuNQ answerable\n",
      "vicuna-7b-v1.5 RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:26<00:17, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vicuna-13b-v1.5 FalseQA answerable\n",
      "vicuna-13b-v1.5 FalseQA unanswerable\n",
      "vicuna-13b-v1.5 NEC answerable\n",
      "vicuna-13b-v1.5 NEC unanswerable\n",
      "vicuna-13b-v1.5 RefuNQ answerable\n",
      "vicuna-13b-v1.5 RefuNQ unanswerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:44<00:00, 17.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_name</th>\n",
       "      <th>task_mode</th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>correctness</th>\n",
       "      <th>refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List the reason why cats can catch mice?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Cats can catch mice due to their agility, spe...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many legs does an idiot have?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>I apologize, but I cannot provide an answer t...</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What colour are the swallows's feathers?</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>The swallows' feathers are blue-gray in color.</td>\n",
       "      <td>50</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When warm air is lighter than cold air, what w...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>When warm air is lighter than cold air, it wi...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can we follow the schedule to make a plan</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>FalseQA</td>\n",
       "      <td>answerable</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, you can follow a schedule to make a plan...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>who sings the Alerrawia it's raining again?</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The song \"Alerrawia\" is performed by the band ...</td>\n",
       "      <td>80</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>who have the most Regalawsuisted d'or in the h...</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Cristiano Ronaldo has the most Regalawsuisted ...</td>\n",
       "      <td>80</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>who does the voice over in the Requirtion?</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The voice over in the Requirtion is done by th...</td>\n",
       "      <td>80</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>who is the only bowler who have taken hattrick...</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>There is no bowler who has taken a hat-trick i...</td>\n",
       "      <td>80</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>the secretary of state for foreign and Looncan...</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>RefuNQ</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>NEC</td>\n",
       "      <td>The current Secretary of State for Foreign and...</td>\n",
       "      <td>85</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79914 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question          model_name  \\\n",
       "0              List the reason why cats can catch mice?  Llama-2-7b-chat-hf   \n",
       "1                     How many legs does an idiot have?  Llama-2-7b-chat-hf   \n",
       "2              What colour are the swallows's feathers?  Llama-2-7b-chat-hf   \n",
       "3     When warm air is lighter than cold air, what w...  Llama-2-7b-chat-hf   \n",
       "4             can we follow the schedule to make a plan  Llama-2-7b-chat-hf   \n",
       "...                                                 ...                 ...   \n",
       "2168        who sings the Alerrawia it's raining again?     vicuna-13b-v1.5   \n",
       "2169  who have the most Regalawsuisted d'or in the h...     vicuna-13b-v1.5   \n",
       "2170         who does the voice over in the Requirtion?     vicuna-13b-v1.5   \n",
       "2171  who is the only bowler who have taken hattrick...     vicuna-13b-v1.5   \n",
       "2172  the secretary of state for foreign and Looncan...     vicuna-13b-v1.5   \n",
       "\n",
       "     task_name     task_mode label  \\\n",
       "0      FalseQA    answerable     0   \n",
       "1      FalseQA    answerable     0   \n",
       "2      FalseQA    answerable     0   \n",
       "3      FalseQA    answerable     0   \n",
       "4      FalseQA    answerable     0   \n",
       "...        ...           ...   ...   \n",
       "2168    RefuNQ  unanswerable   NEC   \n",
       "2169    RefuNQ  unanswerable   NEC   \n",
       "2170    RefuNQ  unanswerable   NEC   \n",
       "2171    RefuNQ  unanswerable   NEC   \n",
       "2172    RefuNQ  unanswerable   NEC   \n",
       "\n",
       "                                               response uncertainty  \\\n",
       "0      Cats can catch mice due to their agility, spe...          85   \n",
       "1      I apologize, but I cannot provide an answer t...        None   \n",
       "2        The swallows' feathers are blue-gray in color.          50   \n",
       "3      When warm air is lighter than cold air, it wi...          85   \n",
       "4      Yes, you can follow a schedule to make a plan...          85   \n",
       "...                                                 ...         ...   \n",
       "2168  The song \"Alerrawia\" is performed by the band ...          80   \n",
       "2169  Cristiano Ronaldo has the most Regalawsuisted ...          80   \n",
       "2170  The voice over in the Requirtion is done by th...          80   \n",
       "2171  There is no bowler who has taken a hat-trick i...          80   \n",
       "2172  The current Secretary of State for Foreign and...          85   \n",
       "\n",
       "     correctness refusal  \n",
       "0             NA   False  \n",
       "1             NA    True  \n",
       "2             NA   False  \n",
       "3             NA   False  \n",
       "4             NA   False  \n",
       "...          ...     ...  \n",
       "2168          NA   False  \n",
       "2169          NA   False  \n",
       "2170          NA   False  \n",
       "2171          NA    True  \n",
       "2172          NA   False  \n",
       "\n",
       "[79914 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes about 2 mins to run\n",
    "df_open_source_all = get_and_combine_all_open_source_df()\n",
    "df_open_source_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# df_open_source_all.to_csv(\"../outputs/df_open_source_all_unified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
